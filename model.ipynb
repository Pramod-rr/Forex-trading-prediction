{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 258 entries, 0 to 257\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Date      258 non-null    object \n",
      " 1   Price     258 non-null    float64\n",
      " 2   Open      258 non-null    float64\n",
      " 3   High      258 non-null    float64\n",
      " 4   Low       258 non-null    float64\n",
      " 5   Vol.      0 non-null      float64\n",
      " 6   Change %  258 non-null    object \n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 14.2+ KB\n"
     ]
    }
   ],
   "source": [
    "eurusd = pd.read_csv('data/EUR_USD Historical Data.csv')\n",
    "eurusd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Price', 'Open', 'High', 'Low', 'Vol.', 'Change %'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eurusd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 258 entries, 0 to 257\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   Date    258 non-null    datetime64[ns]\n",
      " 1   Price   258 non-null    float64       \n",
      " 2   Open    258 non-null    float64       \n",
      " 3   High    258 non-null    float64       \n",
      " 4   Low     258 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(4)\n",
      "memory usage: 10.2 KB\n"
     ]
    }
   ],
   "source": [
    "eurusd = eurusd.drop(columns=['Vol.','Change %'])\n",
    "eurusd.columns = eurusd.columns.str.strip()\n",
    "eurusd['Date'] = pd.to_datetime(eurusd['Date'])\n",
    "eurusd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_data = eurusd.filter(['Price'])\n",
    "df = close_data.values\n",
    "train_size = int(np.ceil(len(df) * .7))#slice data\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "train_data = scaled_data[0:int(train_size), :]\n",
    "# prepare feature and labels\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(60, len(train_data)):\n",
    "    x_train.append(train_data[i-60:i, 0])\n",
    "    y_train.append(train_data[i, 0])\n",
    "\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rnmpr\\Documents\\project n sample\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(units=128, return_sequences=True, input_shape=(x_train.shape[1], 1))))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(units=64, return_sequences=False))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - loss: 0.1672 - mae: 0.3332\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0559 - mae: 0.1820\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0371 - mae: 0.1501\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0257 - mae: 0.1232\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0261 - mae: 0.1233\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0252 - mae: 0.1247\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0183 - mae: 0.0990\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0162 - mae: 0.0985\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0105 - mae: 0.0805\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0133 - mae: 0.0957\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "initial mae 0.27357274293899536 | latest mae: 0.0908128097653389\n",
      "initial loss: 0.12040668725967407 | latest loss: 0.012494013644754887\n"
     ]
    }
   ],
   "source": [
    "print(\"\\ninitial mae {} | latest mae: {}\".format(history.history[\"mae\"][0], history.history[\"mae\"][-1]))\n",
    "print(\"initial loss: {} | latest loss: {}\".format(history.history[\"loss\"][0], history.history[\"loss\"][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step\n",
      "Predictions saved to 'predicted_price.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load trained model\n",
    "model = load_model(\"model.keras\")\n",
    "\n",
    "# Load new data for predictions\n",
    "new_data = pd.read_csv(\"data/EUR_USD Historical Data.csv\")\n",
    "new_data['Date'] = pd.to_datetime(new_data['Date'])\n",
    "new_data.set_index('Date', inplace=True)\n",
    "\n",
    "# Preprocess the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(new_data[['Price']].values)\n",
    "\n",
    "# Prepare data for prediction# Sliding window size\n",
    "lookback = 60\n",
    "X_pred = [scaled_data[i-lookback:i, 0] for i in range(lookback, len(scaled_data))]\n",
    "X_pred = np.array(X_pred).reshape(len(X_pred), lookback, 1)\n",
    "\n",
    "# Predict\n",
    "try:\n",
    "    predictions = model.predict(X_pred)\n",
    "except ValueError as e:\n",
    "    print(\"Error during prediction:\", e)\n",
    "\n",
    "predicted_prices = scaler.inverse_transform(predictions)\n",
    "\n",
    "# Save predictions\n",
    "prediction_dates = new_data.index[lookback:]\n",
    "# Ensure matching lengths\n",
    "min_length = min(len(prediction_dates), len(predicted_prices.flatten()))\n",
    "prediction_dates = prediction_dates[:min_length]\n",
    "predicted_prices = predicted_prices[:min_length]\n",
    "\n",
    "# Create DataFrame\n",
    "results = pd.DataFrame({\"Date\": prediction_dates, \"Predicted_Price\": predicted_prices.round(4).flatten() })\n",
    "results.to_csv(\"predicted_price.csv\", index=False)\n",
    "\n",
    "print(\"Predictions saved to 'predicted_price.csv'\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
